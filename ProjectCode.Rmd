---
title: "Term Project Code"
author: "Lianne Sheppard for ENVH 556"
date: "Winter 2021; Updated `r format(Sys.time(), '%d %B, %Y')`"
output: 
    html_document:
        fig_caption: yes
        toc: true
        toc_depth: 3
        number_sections: true
---

<!--Basic document set-up goes here  -->

```{r setup, include=FALSE}
#-------------r.setup-------------
knitr::opts_chunk$set(echo = TRUE)

```

```{r clear.workspace, eval=FALSE, echo=FALSE}
#---------clear.workspace------------
# Clear the environment without clearing knitr
#
# This chunk is useful for code development because it simulates the knitr
# environment. Run it as a code chunk when testing. When knitr is run, it uses a
# fresh, clean environment, so we set eval=FALSE to disable this chunk when
# rendering.

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
    res <- suppressWarnings(
        lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
               detach, character.only=TRUE, unload=TRUE, force=TRUE))
   
}

```


```{r load.libraries.pacman, echo=FALSE, include=FALSE, eval=TRUE}
#----------------load.libraries.pacman----
# Load pacman into memory, installing as needed
my_repo <- 'http://cran.r-project.org'
if (!require("pacman")) {install.packages("pacman", repos = my_repo)}

# Load the other packages, installing as needed.  Some reasons for packages:
# knitr:  kable()
# ggplot2: part of tidyverse
# readr: part of tidyverse
# dplyr: part of tidyverse
# multcomp:  glht
# modelr:  part of tidyverse and need for add_predictions and add_residuals
# boot:  cv tools are available
# Hmisc:  describe
# lme4
# stringr:  string management functions in tidyverse
# forcats:  factor handling in tidyverse
pacman::p_load(tidyverse, knitr, dplyr,  
               stringr, forcats, Hmisc)  

```

```{r read.datasets.from.a.web.site, eval=TRUE, echo=FALSE}
#-----read.datasets.from.a.web.site--------
# Download the data file from a web site if it is not already downloaded, then
# read in the file
# This version reads in multiple files using a loop

datapath <- "Datasets"
dir.create(datapath, showWarnings=FALSE, recursive = TRUE)

# fn has the file names (before ".rds") to loop over
fn <- c("cohist", "RECpersonal", "jem")

# loop through the files to be read
for (i in seq_along(fn)){
    # define the input file name, linking it to the .rds
    input.file <- str_c(fn[i],".rds")
    
    # define the full path for the dataset
    input.path <- file.path(datapath, input.file)
    
    # Only download the file if it's not already present
   if (!file.exists(input.path)) {
    url <- paste("https://staff.washington.edu/high/envh556/Datasets", 
                 input.file, sep = '/')
    download.file(url = url, destfile = input.path) 
    }

    # Assign the file to an object of the same input name
    # Output a warning message if the file cannot be found
if (file.exists(input.path)) {
    assign(fn[i],readRDS(file = input.path))
} else warning(paste("Can't find", input.file, "!"))

}

```

```{r rename REC, echo = FALSE}
#----- rename REC to simplify references below-----
REC <- RECpersonal
rm(RECpersonal)

```


# Introduction and Context

This is the companion R Markdown file to the JEM procedure overview file:
*JEM_syntax*.  These files describes the general steps for generating a
Job Exposure Matrix (JEM) for REC from the DEMS datasets.  It also addresses
dataset features you need to be aware of during your project.  Other important
aspects of the project are not described here.

There are basically 4 steps to creating the JEM for REC from the DEMS data:   

    a) Predict REC from a model by mine and job,   
    
    b) Predict historical CO from a model by mine and year,   
    
    c) Combine the two sets of predictions into a JEM for each mine, job and year, and   
    
    d) Calculate the predicted historical REC estimates.  

This syntax that we provide for you in this R Markdown file is supposed to be
generic â€“ that is, it will work, but the models we have provided are not
necessarily the best ones to use.  For instance, in the sample code in Section
3, we have fit simple models for all mines combined, and we have also showed you
the methods you would need to predict from these models.  Because there were
some complicated aspects of handling the period factor variables, in Section 4
we repeated parts of this work using period instead of year as the time
variable.   You need to explore and determine the best models, and interpret the
results.

# Data overview

**Basic observations about the datasets and some preliminary data management**

Let's get a quick summary of each dataset to begin to grapple with some of the
data features we will need to address in this project.

```{r tibbles of datasets}
#----- tibbles of datasets -------

as_tibble(REC)

as_tibble(cohist)

as_tibble(jem)

```

Observations about the datasets:

* **Numbers of observations**:  The number of rows in each dataset: 
    - `REC`: 688 
    - `cohist`:  6,040 
    - `jem`:  6,480

* **Facility**:  All datasets have one or two variables to identify facility.
Two of them (`cohist` and `REC`) have two variables while `jem` has only one.
Also the lone facility variable in `jem`, *facilityno* is a factor variable with
the combination of the facility letter and number.  This is also true in `REC`.
However, this variable in `cohist` is only a number.

* **Time**:  REC was only collected during the NIOSH survey and so doesn't have
a time period.  `cohist` has whole years and a variable *period* which is an
integer coded from 2-8.  `jem` has both *year* and *period*.  Coding is
identical for year but the *period* variable is a factor with labels rather than
an integer.  To learn how `cohist` and `jem` definitions of period align, we
need to do a merge and compare them.  See below.

* **Job**:  `jem` has a single variable *job* which is coded the same as the
variable *job* in `REC`.  `REC` has two additional job variables:  *mdj*, the
concatenation of mine (as a number), department, and job, and *job98* which is
not identical to *job* and is an integer variable, a slightly recoded version of
*mdj*.

Here is some code to create a factor variable for faciity in `cohist` that
aligns with the simiar factor variable in the other two datasets.  We also
investigate the period variable in `cohist` and `jem` and then create a new
variable *periodfac* which is a factor variable coded the same across datasets.
(In your analyses be careful to take note of which datasets have which
information and how you will approach this.)

```{r preliminary data management}
#----- preliminary data management------

# get the facilityno factor levels for fixing cohist
fn_levels <- levels(REC$facilityno)

# now create a factor version of facility in cohist
cohist <- cohist %>%
    mutate(
        facilitychar = str_c(facilityid,facilityno),
        facilityfac = factor(facilitychar, levels = fn_levels)) 

# figure out the period variables
# period in cohist
with(cohist, table(year, period))
# observe only 4 observations in period 2 (in 1972), a fair number in periods
# 2-7, and only 15 in period 8
# 
# period in jem
with(jem, table(year, period))
# observe 
#   1. 120 observations per year-period combo
#   2. year starts in 1947, ends in 2003
#   3. periods are:  1 -- 55 (1947-1970)
#           2 -- 71-72 (1971-1975)
#           3 -- 76-79 (1976-1979)
#           4 -- 80-84 (1980-1984)
#           5 -- 85-89 (1985-1989)
#           6 -- 90-94 (1990-1994)
#           7 -- 95-99 (1995-1999)
#           8 -- 2001  (2000-2003)
# merge jem and cohist as an inner join (only keep those that match) and then
# compare period on them
cohist_uniq <- cohist %>%
    group_by(year) %>%
    dplyr::summarize(year_u = first(year),
                     period_u = first(period)
                    )
 #   select(year, period)
testjem <- inner_join(jem, cohist_uniq, "year" = "year_u")
# observe the periods line up in jem and cohist, though there are no cohist data
# for the earliest time period in the jem
with(testjem,table(period, period_u))

# recode the period variables to align across datasets
#period_levels <- c("1947-1970", "1971-1975", "1976-1979", "1980-1984",
#"1985-1989", "1990-1994", "1995-1999", "2000-2003" )
#period_levels_co <- period_levels[-1]
cohist <- mutate(cohist, periodfac = factor(period))
cohist <- cohist %>% mutate(periodfac = fct_recode(periodfac,
            "1971-1975" = "2",
            "1976-1979" = "3",
            "1980-1984" = "4",
            "1985-1989" = "5",
            "1990-1994" = "6",
            "1995-1999" = "7",
            "2000-2003" = "8"))

jem <- jem %>% mutate(periodfac = fct_recode(period,
            "1947-1970" = "55",
            "1971-1975" = "71-72",
            "1976-1979" = "76-79",
            "1980-1984" = "80-84",
            "1985-1989" = "85-89",
            "1990-1994" = "90-94",
            "1995-1999" = "95-99",
            "2000-2003" = "2001"))

```

# Analysis Steps when **Year** is the Time Variable

## REC Models:  

**Predict REC from observations and create a new dataset with an estimated AM
for each mine and job**

###	Create a variable lnrec = ln(ecdata) 

```{r update REC}
#----- update REC -----------
 
# create lnrec
REC$lnrec <- log(REC$ecdata)

```

###	Estimate an AM for each mine and job combination

**Use one of the approaches we learned in class**

We show regression and the MLE estimate of the arithmetic mean (AM) using a
single very simple model with all facilities together.  Your job is to decide
how you want to approach this (e.g what model will you select and why?) using
the tools we have learned over the quarter.  Here are some considerations (some
apply to the CO data also):

* Regression is just one way to do this.  
* How you approach the modeling will affect whether you can predict for all job
and facility combinations.  Think about what predictions you believe are
supported scientifically.
* We have not addressed here how to handle facility J. If you are going to try
to predict at this facility, how will you approach it and why?  (Hint:  You can
consult the DEMS papers for ideas.)

```{r REC regression for prediction}
#----- REC regression for prediction---------
# first create job as a factor variable and set the reference level to be job 410
# 410 is a common job and thus a useful reference category
# relevel easily moves the specified factor to be first or the reference in
# regression
REC$jobf <- factor(REC$job)
#REC$jobf <- fct_relevel(REC$jobf)
#REC$jobf <- fct_relevel(REC$jobf, ref = "410")

# regression
recfit <- lm(lnrec ~ facilityno + jobf, data=REC)

# create a new dataset that has one observation per job and facility
# (Make sure you include all covariates in your regression model)
# 
# Choose one of the following; comment out the other
# The following only picks out the distinct job-facility combinations that exist
# in the dataset, n = 50
#newdat <- REC %>% 
#    select(facilityno, facilityid, job, jobf) %>%
#    distinct()

# Here is the alternative to get all possible values of the facilityno and job
# combinations, n = 105
# Note:  still need to address the missing facility J 
newdat <- with(REC, expand.grid(facilityno = unique(facilityno), jobf = unique(jobf)) )

# prediction over all facilityno job combinations
newrec <- predict(recfit, newdat, se.fit=TRUE)
newdat$lnrec_p <- newrec$fit
newdat$lnrec_pvar <- 
    newrec$se.fit^2 + newrec$residual.scale^2
newdat$rec_AM <- 
    exp(newdat$lnrec_p + newdat$lnrec_pvar/2)
# for getting the above variance of a new obs from predict(), see e.g. https://stackoverflow.com/questions/38109501/how-does-predict-lm-compute-confidence-interval-and-prediction-interval/38110406#38110406
# 
# use this version for the first newdat definition
#RECnew <- newdat %>% 
#    select(facilityno, job, jobf, rec_AM)
# use this version for the second newdat definition
RECnew <- newdat %>% 
    mutate(job = as.numeric(as.character(jobf))) %>%
    select(facilityno, job, jobf, rec_AM)

```


###	Estimate of the AM for each mine and job combination

Use your results from the previous step.

See above.  Combined with the regression and prediction chunk.

## CO models:  By year
**Model CO concentration from observations and create a new dataset with an estimated AM for each mine and *year* (or period)**

###	Estimate an AM for each mine and job combination by time period (categorized or **individual years**).

Use one of the approaches we learned.

We show regression and the MLE estimate of the arithmetic mean (AM) using a
single very simple model with all facilities together.  Your job is to decide
how you want to approach this using the tools we have learned over the quarter.

```{r CO regression for prediction}
#----- CO regression for prediction -------

# a basic regression
simplefit <- lm(lnco ~ facilityfac + as.factor(year), data=cohist)

# prediction over all facilityno year combinations
# Choose one of the following; comment out or delete the other
#
# The following only picks out the distinct year-facility combinations that exist
# in the dataset, n = ADD
#newdat <- cohist %>% 
#    select(facilityfac, facilityno, facilityid, year, period) %>%
#    distinct()

# Here is the alternative to get all possible values of the facilityno and times
# combinations, n = 208
newdat <-
    with(cohist, expand.grid(facilityfac = unique(facilityfac), 
                             year = unique(year)))

# prediction over all facilityfac and year combinations
newco <- predict(simplefit, newdat, se.fit=TRUE)
newdat$lnco_p <- newco$fit
newdat$lnco_pvar <- 
    newco$se.fit^2 + newco$residual.scale^2
newdat$co_AM <- 
    exp(newdat$lnco_p + newdat$lnco_pvar/2)

# create dataset to merge, addressing facilityno isn't a factor variable coded
# the same way as in the other datasets
#
# Use this version for the first newdat definition:
#COnew <- newdat %>%
#    select(facilityno, facilityfac, year, period, co_AM)
# Use this version for the second newdat definition
# Note it drops period
COnew <- newdat %>%
    mutate(facilityno = as.character(facilityfac)) %>%
    select(facilityno, facilityfac, year, co_AM)

```
###	Produce an estimate of the AM for each mine and time combination

Use your results from the previous step.

See above.  Combined with the regression and prediction chunk.

## JEM target file: Put predictions into the JEM

We have created the JEM for you.  It has a record for each combination of job,
year (thus also period) and facilityno.  This step requires that you merge the
data from `REC` and from `cohist` into the JEM.  In `tidyverse`, merging is call
joining.  The syntax below is from `tidyverse`, specifically from the `dplyr`
package.  To learn more about joins, see *R for Data Science*
[R4DS](https://r4ds.had.co.nz/index.html), specifically the chapter on
relational data, [Chapter 13](https://r4ds.had.co.nz/relational-data.html).

An important part of joining datasets is making sure the results you get from
the join are as you expect and are correctly joined.  Make sure you understand
the datasets you are joining, how they relate to each other, and the keys (or
variables) you will use to merge them with.  Keys connect the two datasets or
tables.  They can be comprised of mulitple variables.  For our data, we
ultimately want data merged by time (*year* or *period*), *job*, and facility
(*facilityid* or *facilityno*).  Thus these will make up our key variables.
Note the `REC` dataset only has facility and job, while the `cohist` dataset
only has facility and time.  So the keys in each of those joins will be
different.

### Merge REC into the JEM by facility and job

We will use a left join and join REC into the JEM.  In principle we want to
preserve all rows of the JEM, although if the REC data don't have values we
don't want bogus data to be inserted.  We'd prefer to have those be NAs.  (An
alternative would be to drop row of the JEM that don't match REC.  However, it
is probably easier to keep track of our objectives by keeping all JEM rows and
then addressing later those that don't have data in them.)

```{r leftjoin JEM with REC}
#----- leftjoin JEM with REC------
JEMnew <- left_join(jem, RECnew, by = c("facilityno", "job"))

```

Note:  it is critical that you develop habits to make sure the data you get from
a procedure are what you expect.  This is particularly important after doing a
join.  Add code to the next chunk to check whether you did the matching in the
merge correctly.  You should at least verify the sample sizes indicate whether
you have the data you expect.  Find out whether there are any records without a
match.  Does it make sense to you that these records haven't matched?

```{r check the join of JEM with REC}
#----- check the join of JEM with REC------
# ADD this

```


###	Merge CO into the JEM by facility and time (period or **year**)

```{r leftjoin JEM with CO}
# leftjoin JEM with CO------
JEMnew2 <- left_join(JEMnew, COnew, 
        by = c("facilityno" = "facilityfac", "year"))

```


Make sure to verify you did the merge correctly.  TODO:  

```{r check the join of JEM with CO}
#----- check the join of JEM with CO------
# ADD this

```

## Compute REC for each observation within JEM dataset 

Use a version of the formula in DEMS IV to estimate the REC for each observation
in the JEM dataset
    - Formula:  `rec_mjy = (co_AM / baselineco) * rec_AM`, or in  $\LaTeX$ mode:  
    $$  rec_{mjy} = \frac{co_{AM}}{baselineco} * rec_{AM} $$  
    - Note:  Not all combinations of mine, job, and year have AM estimates,
    therefore you should have missing predictions that you will need to drop.
    In conjuction with this step, make sure you are only missing predictions
    where you expect them to be missing.


```{r predicted REC in JEM}
#----- predicted REC in JEM------

JEM <- JEMnew2 %>%
    mutate(co_ratio = co_AM /baselineco,
           rec_mjy =  co_ratio * rec_AM
           )

```

Some summaries of the final JEM:

```{r describe JEM}
# ----- describe JEM -------
as_tibble(JEM)

describe(JEM)

```

# Analysis Steps when **Period** is the Time Variable

## REC Models:  

**Predict REC from observations and create a new dataset with an estimated AM
for each mine and job**

No changes needed

## CO models:  By period

**Model CO concentration from observations and create a new dataset with an estimated AM for each mine and *period*. **

###	Estimate an AM for each mine and job combination by time period (categorized here). 

Use one of the approaches we learned.

Repeat example regression and the MLE estimate of the arithmetic mean (AM) using
a single very simple model with all facilities together.  This time with period
as the time variable.

```{r CO regression for prediction on period}
#----- CO regression for prediction on period -------

# a basic regression
simplefit <- lm(lnco ~ facilityfac + periodfac, data=cohist)

# prediction over all facilityno period combinations
# Use expand.grid to get all possible values of the facilityno and period
# combinations, n = ADD
newdat <- with(cohist, expand.grid(facilityfac = unique(facilityfac), periodfac = unique(periodfac)))

# prediction over all facilityno year combinations
newco <- predict(simplefit, newdat, se.fit=TRUE)
newdat$lnco_p <- newco$fit
newdat$lnco_pvar <- 
    newco$se.fit^2 + newco$residual.scale^2
newdat$co_AM <- 
    exp(newdat$lnco_p + newdat$lnco_pvar/2)

# create dataset to merge, addressing facilityno isn't a factor variable coded
# like in the other datasets AND that period is coded differently in JEM

# Use this version for the expand.grid newdat definition
# Note it drops year
COnew <- newdat %>%
    mutate(facilityno = as.character(facilityfac)) %>%
    select(facilityno, facilityfac, periodfac, co_AM)

```
###	Produce an estimate of the AM for each mine and time combination

Use your results from the previous step.

See above.  Combined with the regression and prediction chunk.

## JEM target file: Put predictions into the JEM



### Merge REC into the JEM by facility and job

Completed previously.  Result is in `JEMnew`.


###	Merge CO into the JEM by facility and time (**period** or year)

```{r leftjoin JEM with CO by period}
#----- leftjoin JEM with CO by period------
JEMnew2 <- left_join(JEMnew, COnew, 
        by = c("facilityno" = "facilityfac", "periodfac"))

```


Make sure to verify you did the merge correctly.  TODO:  

```{r check the join of JEM with CO by period}
#----- check the join of JEM with CO by period------
# ADD this

```

## Compute REC for each observation within JEM dataset 
Repeat, by period this time.  It is worthwhile to think about whether you can
sensibly fill in data for missing periods and how you will do this.

```{r predicted REC in JEM by period}
#----- predicted REC in JEM by period------

JEM <- JEMnew2 %>%
    mutate(co_ratio = co_AM /baselineco,
           rec_mjy =  co_ratio * rec_AM
           )

```

Some summaries of the final JEM:

```{r describe JEM by period}
# ----- describe JEM by period -------
as_tibble(JEM)

describe(JEM)

```

<!--
TODO:  Understand the reasons behind the somewhat substantial differences in
`co_ratio` estimates between the approach using period and the approach using
year.  While both approaches used fairly simple-minded models, and so there
could be good reasons to see these differences, I'm suspicious that this might
be a clue that there is something that should be corrected.

TODO:  At a minimum it would be worthwhile to look at how these compare with the
numbers given in Table 3 of DEMS IV.
-->

# Appendix

```{r session.info}
#-----session information----

# print R session information
sessionInfo()

```

```{r code.appendix, ref.label = knitr::all_labels(), echo = TRUE, eval = FALSE, , include=TRUE}
#-----code appendix----
```

```{r functions, eval = TRUE}
#-----functions----

# Show the names of all functions defined in the .Rmd
# (e.g. loaded in the environment)
lsf.str()

# Show the definitions of all functions loaded into the current environment  
lapply(c(lsf.str()), getAnywhere)

```

